### 文件代码解读

这个Jupyter Notebook文件的主要内容是一个用于机器翻译任务的Seq2Seq模型训练代码。下面是对文件中关键部分的解读：

#### 数据加载和预处理

```python
# 数据加载函数
def load_data(train_path: str, dev_en_path: str, dev_zh_path: str, test_en_path: str):
    # 读取训练数据
    train_data = read_data(train_path)
    train_en, train_zh = zip(*(line.split('\t') for line in train_data))
    
    # 读取开发集和测试集
    dev_en = read_data(dev_en_path)
    dev_zh = read_data(dev_zh_path)
    test_en = read_data(test_en_path)

    # 预处理数据
    train_processed = preprocess_data(train_en, train_zh)
    dev_processed = preprocess_data(dev_en, dev_zh)
    test_processed = [(en_tokenizer(en.lower())[:MAX_LENGTH], []) for en in test_en if en.strip()]

    # 构建词汇表
    global en_vocab, zh_vocab
    en_vocab, zh_vocab = build_vocab(train_processed)

    # 创建数据集
    train_dataset = TranslationDataset(train_processed, en_vocab, zh_vocab)
    dev_dataset = TranslationDataset(dev_processed, en_vocab, zh_vocab)
    test_dataset = TranslationDataset(test_processed, en_vocab, zh_vocab)
    
    from torch.utils.data import Subset

    # 假设你有10000个样本，你只想用前1000个样本进行测试
    indices = list(range(N))
    train_dataset = Subset(train_dataset, indices)

    # 创建数据加载器
    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)
    dev_loader = DataLoader(dev_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)
    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)

    return train_loader, dev_loader, test_loader
```

这个部分代码实现了数据加载、预处理和词汇表构建。通过读取训练数据、开发集和测试集，进行数据预处理，最后构建词汇表和数据集并创建数据加载器。

#### 模型训练

```python
# 训练模型
def train_model(model, train_loader, dev_loader, optimizer, criterion, n_epochs, clip, save_path):
    for epoch in range(n_epochs):
        model.train()
        epoch_loss = 0
        for batch in train_loader:
            src, trg = batch
            src, trg = src.to(DEVICE), trg.to(DEVICE)
            
            optimizer.zero_grad()
            output = model(src, trg[:, :-1])
            output_dim = output.shape[-1]
            
            output = output.contiguous().view(-1, output_dim)
            trg = trg[:, 1:].contiguous().view(-1)
            
            loss = criterion(output, trg)
            loss.backward()
            
            torch.nn.utils.clip_grad_norm_(model.parameters(), clip)
            optimizer.step()
            
            epoch_loss += loss.item()
        
        dev_loss = evaluate(model, dev_loader, criterion)
        
        print(f'Epoch: {epoch+1}, Train Loss: {epoch_loss/len(train_loader):.3f}, Val. Loss: {dev_loss/len(dev_loader):.3f}')
        
        if epoch == 0 or dev_loss < best_dev_loss:
            best_dev_loss = dev_loss
            torch.save(model.state_dict(), save_path)

    print(f"训练完成！模型已保存到:{save_path}")
```

这个部分代码实现了Seq2Seq模型的训练过程。包括前向传播、计算损失、反向传播和梯度裁剪等步骤，同时在每个epoch结束后进行模型评估并保存最佳模型。

#### 模型评估与翻译

```python
# 计算BLEU分数
# model.load_state_dict(torch.load('../model/best-model.pt'))
# bleu_score = calculate_bleu(dev_loader, en_vocab, zh_vocab, model, DEVICE)
# print(f'BLEU score = {bleu_score:.2f}')
```

这一部分代码展示了如何加载最佳模型并计算BLEU分数进行模型评估。

```python
# 对测试集进行翻译
save_dir = '../results/submit_task2.txt'
with open(save_dir, 'w') as f:
    translated_sentences = []
    for batch in test_loader:  # 遍历所有数据
        src, _ = batch
        src = src.to(DEVICE)
        translated = translate_sentence(src[0], en_vocab, zh_vocab, model, DEVICE, max_length=50)  # 翻译结果,max_length生成翻译的最大长度
        results = "".join(translated)
        f.write(results + '\n')  # 将结果写入文件
    print(f"翻译完成，结果已保存到{save_dir}")
```

这一部分代码展示了如何使用训练好的模型对测试集进行翻译并将结果保存到文件中。

### Seq2Seq模型结构介绍

Seq2Seq（Sequence to Sequence）模型是一种神经网络结构，广泛应用于机器翻译、文本生成等任务。其基本架构包括编码器（Encoder）和解码器（Decoder）两个部分。

#### 编码器-解码器模型原理

1. **编码器（Encoder）**：
   - 接收输入序列，并将其转换为一个固定长度的上下文向量（Context Vector）。
   - 通常使用RNN、LSTM或GRU来实现。

2. **解码器（Decoder）**：
   - 接收编码器生成的上下文向量，并生成目标序列。
   - 在每个时间步长，解码器会生成一个输出，并将该输出作为下一个时间步长的输入。

#### 机器翻译任务的数据预处理

1. **数据清理**：
   - 移除无关字符、标点符号处理等。
   - 将文本转换为小写（或保留原始大小写）。

2. **分词**：
   - 将句子拆分为单词或子词。
   - 使用如BPE（Byte Pair Encoding）等技术进行子词分割。

3. **构建词汇表**：
   - 根据训练数据构建源语言和目标语言的词汇表。
   - 通常会添加特殊标记，如`<pad>`、`<sos>`（句子开始）和`<eos>`（句子结束）。

4. **数据集创建**：
   - 将文本数据转换为数值形式，即索引序列。
   - 使用如PyTorch的Dataset和DataLoader类创建数据集和数据加载器。

#### 模型训练

1. **损失函数**：
   - 通常使用交叉熵损失函数（Cross-Entropy Loss）。
   
2. **优化器**：
   - 常用Adam优化器。

3. **训练循环**：
   - 前向传播：通过编码器和解码器得到预测输出。
   - 计算损失：预测输出与目标输出的差异。
   - 反向传播：更新模型参数。

#### 翻译质量评价

1. **BLEU分数（Bilingual Evaluation Understudy）**：
   - 通过计算预测翻译与参考翻译之间的n-gram匹配程度来评估翻译质量。
   - BLEU分数是机器翻译任务中最常用的评估指标之一。

2. **其他指标**：
   - METEOR、ROUGE等。

通过上述步骤，可以完成一个Seq2Seq模型在机器翻译任务中的构建、训练和评估。




# Let's open the uploaded file and inspect its contents to understand the code.
file_path = '/mnt/data/Task2-baseline-2024-07-16.ipynb'

# Load the notebook content
import json

with open(file_path, 'r', encoding='utf-8') as file:
    notebook_content = json.load(file)

# Extract and print the content for review
notebook_content


# trg_sequences = [item[1] for item in batch]\n',
    '    \n',
    "    en_batch = nn.utils.rnn.pad_sequence(en_batch, batch_first=True, padding_value=en_vocab['<pad>'])\n",
    "    zh_batch = nn.utils.rnn.pad_sequence(zh_batch, batch_first=True, padding_value=zh_vocab['<pad>'])\n",
    '\n',
    "    # en_batch = pad_sequence(en_batch, batch_first=True, padding_value=en_vocab['<pad>'])\n",
    "    # zh_batch = pad_sequence(zh_batch, batch_first=True, padding_value=zh_vocab['<pad>'])\n",
    '    \n',
    '    return en_batch, zh_batch']},
  {'cell_type': 'code',
   'execution_count': 7,
   'metadata': {},
   'outputs': [],
   'source': ['# 数据加载函数\n',
    'def load_data(train_path: str, dev_en_path: str, dev_zh_path: str, test_en_path: str):\n',
    '    # 读取训练数据\n',
    '    train_data = read_data(train_path)\n',
    "    train_en, train_zh = zip(*(line.split('\\t') for line in train_data))\n",
    '    \n',
    '    # 读取开发集和测试集\n',
 '    dev_en = read_data(dev_en_path)\n',
    '    dev_zh = read_data(dev_zh_path)\n',
    '    test_en = read_data(test_en_path)\n',
    '\n',
    '    # 预处理数据\n',
    '    train_processed = preprocess_data(train_en, train_zh)\n',
    '    dev_processed = preprocess_data(dev_en, dev_zh)\n',
    '    test_processed = [(en_tokenizer(en.lower())[:MAX_LENGTH], []) for en in test_en if en.strip()]\n',
    '\n',
    '    # 构建词汇表\n',
    '    global en_vocab, zh_vocab\n',
    '    en_vocab, zh_vocab = build_vocab(train_processed)\n',
    '\n',
    '    # 创建数据集\n',
    '    train_dataset = TranslationDataset(train_processed, en_vocab, zh_vocab)\n',
    '    dev_dataset = TranslationDataset(dev_processed, en_vocab, zh_vocab)\n',
    '    test_dataset = TranslationDataset(test_processed, en_vocab, zh_vocab)\n',
    '    \n',
    '    from torch.utils.data import Subset\n',
    '\n',
    '    # 假设你有10000个样本，你只想用前1000个样本进行测试\n',
    '    indices = list(range(N))\n',
    '    train_dataset = Subset(train_dataset, indices)\n',
    '\n',
    '    # 创建数据加载器\n',
    '    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn, drop_last=True)\n',
    '    dev_loader = DataLoader(dev_dataset, batch_size=BATCH_SIZE, collate_fn=collate_fn, drop_last=True)\n',
    '    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, collate_fn=collate_fn, drop_last=True)\n',
    '\n',
    '    return train_loader, dev_loader, test_loader, en_vocab, zh_vocab']},
  {'cell_type': 'code',
   'execution_count': 7,
   'metadata': {},
   'outputs': [],
   'source': ['# def pad_sequence(batch,batch_first,padding_value):\n',
    '#     # 对源语言和目标语言序列分别进行填充\n',
    '#     src_sequences = [item[0] for item in batch]\n',
    '#     trg_sequences = [item[1] for item in batch]\n',
    '    \n',
    "#     src_padded = nn.utils.rnn.pad_sequence(src_sequences, batch_first=True, padding_value=en_vocab['<pad>'])\n",
    "#     trg_padded = nn.utils.rnn.pad_sequence(trg_sequences, batch_first=True, padding_value=zh_vocab['<pad>'])\n",
    '    \n',
    '#     return src_padded, trg_padded\n',
    '\n']},
  {'cell_type': 'markdown', 'metadata': {}, 'source': ['## 模型构建']},
  {'cell_type': 'code',
   'execution_count': 8,
   'metadata': {},
   'outputs': [],
   'source': ['\n',
    'class Encoder(nn.Module):\n',
    '    def __init__(self, input_dim, emb_dim, hid_dim, n_layers, dropout):\n',
    '        super().__init__()\n',
    '        self.hid_dim = hid_dim\n',
    '        self.n_layers = n_layers\n',
    '        \n',
    '        self.embedding = nn.Embedding(input_dim, emb_dim)\n',
    '        self.gru = nn.GRU(emb_dim, hid_dim, n_layers, dropout=dropout, batch_first=True)\n',
    '        self.dropout = nn.Dropout(dropout)\n',
    '        \n',
    '    def forward(self, src):\n',
    '        # src = [batch size, src len]\n',
    '        embedded = self.dropout(self.embedding(src))\n',
    '        # embedded = [batch size, src len, emb dim]\n',
    '        \n',
    '        outputs, hidden = self.gru(embedded)\n',
    '        # outputs = [batch size, src len, hid dim * n directions]\n',
    '        # hidden = [n layers * n directions, batch size, hid dim]\n',
    '        \n',
    '        return outputs, hidden\n',
    '\n',
    'class Attention(nn.Module):\n',
    '    def __init__(self, hid_dim):\n',
    '        super().__init__()\n',
    '        self.attn = nn.Linear(hid_dim * 2, hid_dim)\n',
 '        self.v = nn.Linear(hid_dim, 1, bias=False)\n',
    '        \n',
    '    def forward(self, hidden, encoder_outputs):\n',
    '        # hidden = [1, batch size, hid dim]\n',
    '        # encoder_outputs = [batch size, src len, hid dim]\n',
    '        \n',
    '        batch_size = encoder_outputs.shape[0]\n',
    '        src_len = encoder_outputs.shape[1]\n',
    '        \n',
    '        hidden = hidden.repeat(src_len, 1, 1).transpose(0, 1)\n',
    '        # hidden = [batch size, src len, hid dim]\n',
    '        \n',
    '        energy = torch.tanh(self.attn(torch.cat((hidden, encoder_outputs), dim=2)))\n',
    '        # energy = [batch size, src len, hid dim]\n',
    '        \n',
    '        attention = self.v(energy).squeeze(2)\n',
    '        # attention = [batch size, src len]\n',
    '        \n',
    '        return F.softmax(attention, dim=1)\n',
    '\n',
    'class Decoder(nn.Module):\n',
    '    def __init__(self, output_dim, emb_dim, hid_dim, n_layers, dropout, attention):\n',
    '        super().__init__()\n',
    '        self.output_dim = output_dim\n',
    '        self.hid_dim = hid_dim\n',
    '        self.n_layers = n_layers\n',
    '        self.attention = attention\n',
    '        \n',
    '        self.embedding = nn.Embedding(output_dim, emb_dim)\n',
    '        self.gru = nn.GRU(hid_dim + emb_dim, hid_dim, n_layers, dropout=dropout, batch_first=True)\n',
    '        self.fc_out = nn.Linear(hid_dim * 2 + emb_dim, output_dim)\n',
    '        self.dropout = nn.Dropout(dropout)\n',
    '        \n',
    '    def forward(self, input, hidden, encoder_outputs):\n',
    '        # input = [batch size, 1]\n',
    '        # hidden = [n layers, batch size, hid dim]\n',
    '        # encoder_outputs = [batch size, src len, hid dim]\n',
    '        \n',
    '        input = input.unsqueeze(1)\n',
    '        embedded = self.dropout(self.embedding(input))\n',
    '        # embedded = [batch size, 1, emb dim]\n',
    '        \n',
    '        a = self.attention(hidden[-1:], encoder_outputs)\n',
    '        # a = [batch size, src len]\n',
    '        \n',
    '        a = a.unsqueeze(1)\n',
    '        # a = [batch size, 1, src len]\n',
    '        \n',
    '        weighted = torch.bmm(a, encoder_outputs)\n',
    '        # weighted = [batch size, 1, hid dim]\n',
    '        \n',
    '        rnn_input = torch.cat((embedded, weighted), dim=2)\n',
    '        # rnn_input = [batch size, 1, emb dim + hid dim]\n',
    '        \n',
    '        output, hidden = self.gru(rnn_input, hidden)\n',
    '        # output = [batch size, 1, hid dim]\n',
    '        # hidden = [n layers, batch size, hid dim]\n',
    '        \n',
    '        embedded = embedded.squeeze(1)\n',
    '        output = output.squeeze(1)\n',
    '        weighted = weighted.squeeze(1)\n',
    '        \n',
    '        prediction = self.fc_out(torch.cat((output, weighted, embedded), dim=1))\n',
    '        # prediction = [batch size, output dim]\n',
    '        \n',
    '        return prediction, hidden\n',
    '\n',
    'class Seq2Seq(nn.Module):\n',
    '    def __init__(self, encoder, decoder, device):\n',
    '        super().__init__()\n',
    '        self.encoder = encoder\n',
    '        self.decoder = decoder\n',
    '        self.device = device\n',
    '        \n',
'    def forward(self, src, trg, teacher_forcing_ratio=0.5):\n',
    '        # src = [batch size, src len]\n',
    '        # trg = [batch size, trg len]\n',
    '        \n',
    '        batch_size = src.shape[0]\n',
    '        trg_len = trg.shape[1]\n',
    '        trg_vocab_size = self.decoder.output_dim\n',
    '        \n',
    '        outputs = torch.zeros(batch_size, trg_len, trg_vocab_size).to(self.device)\n',
    '        encoder_outputs, hidden = self.encoder(src)\n',
    '        \n',
    '        input = trg[:, 0]\n',
    '        \n',
    '        for t in range(1, trg_len):\n',
    '            output, hidden = self.decoder(input, hidden, encoder_outputs)\n',
    '            outputs[:, t] = output\n',
    '            teacher_force = random.random() < teacher_forcing_ratio\n',
    '            top1 = output.argmax(1)\n',
    '            input = trg[:, t] if teacher_force else top1\n',
    '        \n',
    '        return outputs']},
  {'cell_type': 'code',
   'execution_count': 9,
   'metadata': {},
   'outputs': [],
   'source': ['\n',
    '# 初始化模型\n',
    'def initialize_model(input_dim, output_dim, emb_dim, hid_dim, n_layers, dropout, device):\n',
    '    attn = Attention(hid_dim)\n',
    '    enc = Encoder(input_dim, emb_dim, hid_dim, n_layers, dropout)\n',
    '    dec = Decoder(output_dim, emb_dim, hid_dim, n_layers, dropout, attn)\n',
    '    model = Seq2Seq(enc, dec, device).to(device)\n',
    '    return model\n']},
  {'cell_type': 'markdown', 'metadata': {}, 'source': ['## 训练']},
  {'cell_type': 'code',
   'execution_count': 10,
   'metadata': {},
   'outputs': [],
   'source': ['# # 定义优化器\n',
    '# def initialize_optimizer(model, learning_rate=0.001):\n',
    '#     return optim.Adam(model.parameters(), lr=learning_rate)']},
  {'cell_type': 'code',
   'execution_count': 11,
   'metadata': {},
   'outputs': [],
   'source': ['# 运行时间\n',
    'def epoch_time(start_time, end_time):\n',
    '    elapsed_time = end_time - start_time\n',
    '    elapsed_mins = int(elapsed_time / 60)\n',
    '    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n',
    '    return elapsed_mins, elapsed_secs']},
  {'cell_type': 'code',
   'execution_count': 12,
   'metadata': {},
   'outputs': [],
   'source': ['def train(model, iterator, optimizer, criterion, clip):\n',
    '    model.train()\n',
    '    epoch_loss = 0\n',
    '    \n',
    '    for i, batch in enumerate(iterator):\n',
    '        #print(f"Training batch {i}")\n',
    '        src, trg = batch\n',
    '        #print(f"Source shape before: {src.shape}, Target shape before: {trg.shape}")\n',
    '        if src.numel() == 0 or trg.numel() == 0:\n',
    '            #print("Empty batch detected, skipping...")\n',
    '            continue  # 跳过空的批次\n',
    '        \n',
    '        src, trg = src.to(DEVICE), trg.to(DEVICE)\n',
    '        \n',
    '        optimizer.zero_grad()\n',
    '        output = model(src, trg)\n',
    '        \n',
    '        output_dim = output.shape[-1]\n',
    '        output = output[:, 1:].contiguous().view(-1, output_dim)\n',
    '        trg = trg[:, 1:].contiguous().view(-1)\n',
    '        \n',
    '        loss = criterion(output, trg)\n',
    '        loss.backward()\n',
    '        \n',
'        clip_grad_norm_(model.parameters(), clip)\n',
    '        optimizer.step()\n',
    '        \n',
    '        epoch_loss += loss.item()\n',
    '\n',
    '    print(f"Average loss for this epoch: {epoch_loss / len(iterator)}")\n',
    '    return epoch_loss / len(iterator)\n',
    '\n',
    'def evaluate(model, iterator, criterion):\n',
    '    model.eval()\n',
    '    epoch_loss = 0\n',
    '    with torch.no_grad():\n',
    '        for i, batch in enumerate(iterator):\n',
    '            #print(f"Evaluating batch {i}")\n',
    '            src, trg = batch\n',
    '            if src.numel() == 0 or trg.numel() == 0:\n',
    '                continue  # 跳过空批次\n',
    '            \n',
    '            src, trg = src.to(DEVICE), trg.to(DEVICE)\n',
    '            \n',
    '            output = model(src, trg, 0)  # 关闭 teacher forcing\n',
    '            \n',
    '            output_dim = output.shape[-1]\n',
    '            output = output[:, 1:].contiguous().view(-1, output_dim)\n',
    '            trg = trg[:, 1:].contiguous().view(-1)\n',
    '            \n',
    '            loss = criterion(output, trg)\n',
    '            epoch_loss += loss.item()\n',
    '        \n',
    '    return epoch_loss / len(iterator)']},
  {'cell_type': 'code',
   'execution_count': 22,
   'metadata': {},
   'outputs': [],
   'source': ['# 翻译函数\n',
    'def translate_sentence(src_indexes, src_vocab, tgt_vocab, model, device, max_length=50):\n',
    '    model.eval()\n',
    '    \n',
    '    src_tensor = src_indexes.unsqueeze(0).to(device)  # 添加批次维度\n',
    '    \n',
    '    # with torch.no_grad():\n',
    '    #     encoder_outputs = model.encoder(model.positional_encoding(model.src_embedding(src_tensor) * math.sqrt(model.d_model)))\n',
    '\n',
    "    trg_indexes = [tgt_vocab['<bos>']]\n",
    '    for i in range(max_length):\n',
    '        trg_tensor = torch.LongTensor(trg_indexes).unsqueeze(0).to(device)\n',
    '        # print("src_tensor:",src_tensor)\n',
    '        # print("trg_tensor:",trg_tensor)\n',
    '        with torch.no_grad():\n',
    '            output = model(src_tensor, trg_tensor)\n',
    '        \n',
    '        pred_token = output.argmax(2)[:, -1].item()\n',
    '        trg_indexes.append(pred_token)\n',
    '        \n',
    "        if pred_token == tgt_vocab['<eos>']:\n",
    '            break\n',
    '    \n',
    '    trg_tokens = [tgt_vocab.get_itos()[i] for i in trg_indexes]\n',
    '    return trg_tokens[1:-1]  # 移除<bos>和<eos>标记']},
  {'cell_type': 'code',
   'execution_count': 14,
   'metadata': {},
   'outputs': [],
   'source': ['def calculate_bleu(dev_loader, src_vocab, tgt_vocab, model, device):\n',
    '    model.eval()\n',
    '    translations = []\n',
    '    references = []\n',
    '    \n',
    '    with torch.no_grad():\n',
    '        for src, tgt in dev_loader:\n',
    '            src = src.to(device)\n',
    '            for sentence in src:\n',
    '                translated = translate_sentence(sentence, src_vocab, tgt_vocab, model, device)\n',
    "                translations.append(' '.join(translated))\n",
    '            \n',
    '            for reference in tgt:\n',
"                ref_tokens = [tgt_vocab.get_itos()[idx] for idx in reference if idx not in [tgt_vocab['<bos>'], tgt_vocab['<eos>'], tgt_vocab['<pad>']]]\n",
    "                references.append([' '.join(ref_tokens)])\n",
    '    \n',
    '    bleu = sacrebleu.corpus_bleu(translations, references)\n',
    '    return bleu.score']},
  {'cell_type': 'code',
   'execution_count': 15,
   'metadata': {},
   'outputs': [],
   'source': ['# 主训练循环\n',
    "def train_model(model, train_iterator, valid_iterator, optimizer, criterion, N_EPOCHS = 10, CLIP = 1, save_path = '../model/best-model.pt'):\n",
    "    best_valid_loss = float('inf')\n",
    '    \n',
    '    for epoch in range(N_EPOCHS):\n',
    '        start_time = time.time()\n',
    '        \n',
    '        #print(f"Starting Epoch {epoch + 1}")\n',
    '        train_loss = train(model, train_iterator, optimizer, criterion, CLIP)\n',
    '        valid_loss = evaluate(model, valid_iterator, criterion)\n',
    '        \n',
    '        end_time = time.time()\n',
    '        epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n',
    '        \n',
    '        if valid_loss < best_valid_loss:\n',
    '            best_valid_loss = valid_loss\n',
    '            torch.save(model.state_dict(), save_path)\n',
    '        \n',
    "        print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
    "        print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
    "        print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')"]},
  {'cell_type': 'code',
   'execution_count': 17,
   'metadata': {},
   'outputs': [{'name': 'stdout',
     'output_type': 'stream',
     'text': ['英语词汇表大小: 44850\n',
      '中文词汇表大小: 75172\n',
      '训练集大小: 100\n',
      '开发集大小: 1000\n',
      '测试集大小: 1000\n']}],
   'source': ['# 定义常量\n',
    'MAX_LENGTH = 100  # 最大句子长度\n',
    'BATCH_SIZE = 32\n',
    "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    'N = 1000   # 采样训练集的数量，最大148363\n',
    '\n',
    "train_path = '../dataset/train.txt'\n",
    "dev_en_path = '../dataset/dev_en.txt'\n",
    "dev_zh_path = '../dataset/dev_zh.txt'\n",
    "test_en_path = '../dataset/test_en.txt'\n",
    '\n',
    'train_loader, dev_loader, test_loader, en_vocab, zh_vocab = load_data(\n',
    '    train_path, dev_en_path, dev_zh_path, test_en_path\n',
    ')\n',
    '\n',
    '\n',
    'print(f"英语词汇表大小: {len(en_vocab)}")\n',
    'print(f"中文词汇表大小: {len(zh_vocab)}")\n',
    'print(f"训练集大小: {len(train_loader.dataset)}")\n',
    'print(f"开发集大小: {len(dev_loader.dataset)}")\n',
    'print(f"测试集大小: {len(test_loader.dataset)}")']},
  {'cell_type': 'code',
   'execution_count': None,
   'metadata': {},
   'outputs': [],
   'source': ['# 主函数\n',
    "if __name__ == '__main__':\n",
    '    \n',
    '    N_EPOCHS = 5\n',
    '    CLIP=1\n',
    '    # 模型参数\n',
    '    INPUT_DIM = len(en_vocab)\n',
    '    OUTPUT_DIM = len(zh_vocab)\n',
    '    EMB_DIM = 128\n',
    '    HID_DIM = 256\n',
    '    N_LAYERS = 2\n',
    '    DROPOUT = 0.5\n',
    '    \n',
    '    # 初始化模型\n',
    '    model = initialize_model(INPUT_DIM, OUTPUT_DIM, EMB_DIM, HID_DIM, N_LAYERS, DROPOUT, DEVICE)\n',
    "    print(f'The model has {sum(p.numel() for p in model.parameters() if p.requires_grad):,} trainable parameters')\n",
    '\n',
    '    # 定义损失函数\n',
    "    criterion = nn.CrossEntropyLoss(ignore_index=zh_vocab['<pad>'])\n",
    '    # 初始化优化器\n',
    '    optimizer = optim.Adam(model.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)\n',
    '\n',
    '    # 训练模型\n',
    "    save_path = '../model/best-model.pt'\n",
    '    train_model(model, train_loader, dev_loader, optimizer, criterion, N_EPOCHS, CLIP, save_path = save_path)\n',
    '\n',
    '    print(f"训练完成！模型已保存到:{save_path}")']},
  {'cell_type': 'markdown', 'metadata': {}, 'source': ['## 在开发集上进行评价']},
  {'cell_type': 'code',
   'execution_count': None,
   'metadata': {},
   'outputs': [],
   'source': ['# # 加载最佳模型\n',
    "# model.load_state_dict(torch.load('../model/best-model.pt'))\n",
    '\n',
    '# # 计算BLEU分数\n',
    '# bleu_score = calculate_bleu(dev_loader, en_vocab, zh_vocab, model, DEVICE)\n',
    "# print(f'BLEU score = {bleu_score:.2f}')\n"]},
  {'cell_type': 'markdown', 'metadata': {}, 'source': ['## 对测试集进行翻译']},
  {'cell_type': 'code',
   'execution_count': None,
   'metadata': {},
   'outputs': [],
   'source': ['# 加载最佳模型\n',
    "#model.load_state_dict(torch.load('../model/best-model_test.pt'))"]},
  {'cell_type': 'code',
   'execution_count': None,
   'metadata': {},
   'outputs': [],
   'source': ["save_dir = '../results/submit_task2.txt'\n",
    "with open(save_dir, 'w') as f:\n",
    '    translated_sentences = []\n',
    '    for batch in test_loader:  # 遍历所有数据\n',
    '        src, _ = batch\n',
    '        src = src.to(DEVICE)\n',
    '        translated = translate_sentence(src[0], en_vocab, zh_vocab, model, DEVICE, max_length=50)  # 翻译结果,max_length生成翻译的最大长度\n',
    '        #print(translated)\n',
    '        results = "".join(translated)\n',
    "        f.write(results + '\\n')  # 将结果写入文件\n",
    '    print(f"翻译完成，结果已保存到{save_dir}")']},
  {'cell_type': 'code',
   'execution_count': None,
   'metadata': {},
   'outputs': [],
   'source': []}],
 'metadata': {'kernelspec': {'display_name': 'glm4',
   'language': 'python',
   'name': 'python3'},
  'language_info': {'codemirror_mode': {'name': 'ipython', 'version': 3},
   'file_extension': '.py',
   'mimetype': 'text/x-python',
   'name': 'python',
   'nbconvert_exporter': 'python',
   'pygments_lexer': 'ipython3',
   'version': '3.12.3'}},
 'nbformat': 4,
 'nbformat_minor': 2}
"                ref_tokens = [tgt_vocab.get_itos()[idx] for idx in reference if idx not in [tgt_vocab['<bos>'], tgt_vocab['<eos>'], tgt_vocab['<pad>']]]\n",
    "                references.append([' '.join(ref_tokens)])\n",
    '    \n',
    '    bleu = sacrebleu.corpus_bleu(translations, references)\n',
    '    return bleu.score']},
  {'cell_type': 'code',
   'execution_count': 15,
   'metadata': {},
   'outputs': [],
   'source': ['# 主训练循环\n',
    "def train_model(model, train_iterator, valid_iterator, optimizer, criterion, N_EPOCHS = 10, CLIP = 1, save_path = '../model/best-model.pt'):\n",
    "    best_valid_loss = float('inf')\n",
    '    \n',
    '    for epoch in range(N_EPOCHS):\n',
    '        start_time = time.time()\n',
    '        \n',
    '        #print(f"Starting Epoch {epoch + 1}")\n',
    '        train_loss = train(model, train_iterator, optimizer, criterion, CLIP)\n',
    '        valid_loss = evaluate(model, valid_iterator, criterion)\n',
    '        \n',
    '        end_time = time.time()\n',
    '        epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n',
    '        \n',
    '        if valid_loss < best_valid_loss:\n',
    '            best_valid_loss = valid_loss\n',
    '            torch.save(model.state_dict(), save_path)\n',
    '        \n',
    "        print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
    "        print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
    "        print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')"]},
  {'cell_type': 'code',
   'execution_count': 17,
   'metadata': {},
   'outputs': [{'name': 'stdout',
     'output_type': 'stream',
     'text': ['英语词汇表大小: 44850\n',
      '中文词汇表大小: 75172\n',
      '训练集大小: 100\n',
      '开发集大小: 1000\n',
      '测试集大小: 1000\n']}],
   'source': ['# 定义常量\n',
    'MAX_LENGTH = 100  # 最大句子长度\n',
    'BATCH_SIZE = 32\n',
    "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    'N = 1000   # 采样训练集的数量，最大148363\n',
    '\n',
    "train_path = '../dataset/train.txt'\n",
    "dev_en_path = '../dataset/dev_en.txt'\n",
    "dev_zh_path = '../dataset/dev_zh.txt'\n",
    "test_en_path = '../dataset/test_en.txt'\n",
    '\n',
    'train_loader, dev_loader, test_loader, en_vocab, zh_vocab = load_data(\n',
    '    train_path, dev_en_path, dev_zh_path, test_en_path\n',
    ')\n',
    '\n',
    '\n',
    'print(f"英语词汇表大小: {len(en_vocab)}")\n',
    'print(f"中文词汇表大小: {len(zh_vocab)}")\n',
    'print(f"训练集大小: {len(train_loader.dataset)}")\n',
    'print(f"开发集大小: {len(dev_loader.dataset)}")\n',
    'print(f"测试集大小: {len(test_loader.dataset)}")']},
  {'cell_type': 'code',
   'execution_count': None,
   'metadata': {},
   'outputs': [],
   'source': ['# 主函数\n',
    "if __name__ == '__main__':\n",
    '    \n',
    '    N_EPOCHS = 5\n',
    '    CLIP=1\n',
    '    # 模型参数\n',
    '    INPUT_DIM = len(en_vocab)\n',
    '    OUTPUT_DIM = len(zh_vocab)\n',
    '    EMB_DIM = 128\n',
    '    HID_DIM = 256\n',
    '    N_LAYERS = 2\n',
    '    DROPOUT = 0.5\n',
    '    \n',
    '    # 初始化模型\n',
    '    model = initialize_model(INPUT_DIM, OUTPUT_DIM, EMB_DIM, HID_DIM, N_LAYERS, DROPOUT, DEVICE)\n',
    "    print(f'The model has {sum(p.numel() for p in model.parameters() if p.requires_grad):,} trainable parameters')\n",
    '\n',
    '    # 定义损失函数\n',
    "    criterion = nn.CrossEntropyLoss(ignore_index=zh_vocab['<pad>'])\n",
    '    # 初始化优化器\n',
    '    optimizer = optim.Adam(model.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)\n',
    '\n',
    '    # 训练模型\n',
    "    save_path = '../model/best-model.pt'\n",
    '    train_model(model, train_loader, dev_loader, optimizer, criterion, N_EPOCHS, CLIP, save_path = save_path)\n',
    '\n',
    '    print(f"训练完成！模型已保存到:{save_path}")']},
  {'cell_type': 'markdown', 'metadata': {}, 'source': ['## 在开发集上进行评价']},
  {'cell_type': 'code',
   'execution_count': None,
   'metadata': {},
   'outputs': [],
   'source': ['# # 加载最佳模型\n',
    "# model.load_state_dict(torch.load('../model/best-model.pt'))\n",
    '\n',
    '# # 计算BLEU分数\n',
    '# bleu_score = calculate_bleu(dev_loader, en_vocab, zh_vocab, model, DEVICE)\n',
    "# print(f'BLEU score = {bleu_score:.2f}')\n"]},
  {'cell_type': 'markdown', 'metadata': {}, 'source': ['## 对测试集进行翻译']},
  {'cell_type': 'code',
   'execution_count': None,
   'metadata': {},
   'outputs': [],
   'source': ['# 加载最佳模型\n',
    "#model.load_state_dict(torch.load('../model/best-model_test.pt'))"]},
  {'cell_type': 'code',
   'execution_count': None,
   'metadata': {},
   'outputs': [],
   'source': ["save_dir = '../results/submit_task2.txt'\n",
    "with open(save_dir, 'w') as f:\n",
    '    translated_sentences = []\n',
    '    for batch in test_loader:  # 遍历所有数据\n',
    '        src, _ = batch\n',
    '        src = src.to(DEVICE)\n',
    '        translated = translate_sentence(src[0], en_vocab, zh_vocab, model, DEVICE, max_length=50)  # 翻译结果,max_length生成翻译的最大长度\n',
    '        #print(translated)\n',
    '        results = "".join(translated)\n',
    "        f.write(results + '\\n')  # 将结果写入文件\n",
    '    print(f"翻译完成，结果已保存到{save_dir}")']},
  {'cell_type': 'code',
   'execution_count': None,
   'metadata': {},
   'outputs': [],
   'source': []}],
 'metadata': {'kernelspec': {'display_name': 'glm4',
   'language': 'python',
   'name': 'python3'},
  'language_info': {'codemirror_mode': {'name': 'ipython', 'version': 3},
   'file_extension': '.py',
   'mimetype': 'text/x-python',
   'name': 'python',
   'nbconvert_exporter': 'python',
   'pygments_lexer': 'ipython3',
   'version': '3.12.3'}},
 'nbformat': 4,
 'nbformat_minor': 2}
